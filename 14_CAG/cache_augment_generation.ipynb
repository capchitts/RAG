{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a86aa13",
   "metadata": {},
   "source": [
    "### What is Cache-Augmented Generation (CAG)?\n",
    "CAG is a retrieval-free approach that bypasses the usual step of querying external knowledge sources at inference time. Instead, it preloads relevant documents into the LLM's extended context window, precomputes the model’s key‑value (KV) cache, and reuses this during inference—so the model can generate responses without additional retrieval steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e6e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# LLM Initialization\n",
    "llm=ChatGroq(model=\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cache variable\n",
    "Model_Cache={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48802156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def cache_model(query):\n",
    "    start_time=time.time()\n",
    "    if Model_Cache.get(query):\n",
    "        print(\"**CAche Hit**\")\n",
    "        end_time=time.time()\n",
    "        elapsed_time=end_time-start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed_time:.2f} seconds\")\n",
    "        return Model_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        Model_Cache[query] = response\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b3c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 0.68 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"hi\". We should greet back. Also follow policies. Simple.'}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 72, 'total_tokens': 116, 'completion_time': 0.087659463, 'prompt_time': 0.002468711, 'queue_time': 0.054266639, 'total_time': 0.090128174}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--39c83a2d-19a4-44e0-b149-d31adb8e2126-0', usage_metadata={'input_tokens': 72, 'output_tokens': 44, 'total_tokens': 116})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6407acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"hi\". We should greet back. Also follow policies. Simple.'}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 72, 'total_tokens': 116, 'completion_time': 0.087659463, 'prompt_time': 0.002468711, 'queue_time': 0.054266639, 'total_time': 0.090128174}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--39c83a2d-19a4-44e0-b149-d31adb8e2126-0', usage_metadata={'input_tokens': 72, 'output_tokens': 44, 'total_tokens': 116})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32188896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"hi\". We should greet back. Also follow policies. Simple.'}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 72, 'total_tokens': 116, 'completion_time': 0.087659463, 'prompt_time': 0.002468711, 'queue_time': 0.054266639, 'total_time': 0.090128174}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--39c83a2d-19a4-44e0-b149-d31adb8e2126-0', usage_metadata={'input_tokens': 72, 'output_tokens': 44, 'total_tokens': 116})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d65ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 3.60 seconds\n",
      "content='**LangGraph: A 500‑Word Overview of the Emerging Framework for Building LLM‑Powered Applications**\\n\\nLangGraph is an open‑source Python library that extends the capabilities of LangChain by providing a graph‑oriented abstraction for orchestrating large language model (LLM) workflows. While LangChain introduced the notion of “chains” – linear sequences of prompts, tools, and memory – LangGraph adds a richer, more flexible topology: nodes represent individual computational steps (LLM calls, API invocations, data transformations, etc.), and edges define the flow of information between them. This graph‑centric view makes it easier to model complex, branching, and iterative reasoning patterns that are common in real‑world AI products.\\n\\n### Core Concepts\\n\\n1. **Nodes** – The atomic units of execution. A node can be:\\n   * **LLMNode** – wraps a prompt template, model, and optional output parsers.\\n   * **ToolNode** – calls an external function, API, or a custom Python routine.\\n   * **MemoryNode** – reads or writes to a persistent store (vector DB, key‑value cache, etc.).\\n   * **ConditionalNode** – evaluates a boolean expression and routes execution accordingly.\\n\\n2. **Edges** – Directed connections that pass data from one node’s output to another’s input. Edges can be annotated with transformation functions (e.g., “extract the `answer` field from the JSON payload”) so that downstream nodes receive exactly what they need.\\n\\n3. **State** – A mutable dictionary that lives throughout the graph run. Each node can read from or write to the state, enabling “memory” across multiple hops without the need for explicit chaining.\\n\\n4. **Execution Engine** – The runtime that traverses the graph. It supports:\\n   * **Depth‑first** or **breadth‑first** traversal.\\n   * **Parallel execution** of independent branches (leveraging asyncio or thread pools).\\n   * **Dynamic branching** where the next node is chosen at runtime based on model output or external conditions.\\n\\n5. **Serialization** – Graph definitions can be saved as JSON or YAML, allowing versioning, sharing, and deployment across environments.\\n\\n### Why a Graph Matters\\n\\nTraditional chain‑based pipelines excel at straightforward “prompt → response” flows, but many production scenarios require more sophisticated control flow:\\n\\n* **Iterative refinement** – A model may need to revise its answer after checking a knowledge base. LangGraph lets you loop back from a verification node to a generation node until a confidence threshold is met.\\n* **Multi‑modal reasoning** – Combining text generation, image analysis, and structured data lookup can be expressed as parallel sub‑graphs that synchronize at a merging node.\\n* **Conditional logic** – Business rules (e.g., “if the user is premium, call the premium‑rate API”) are naturally encoded with ConditionalNode edges.\\n* **Error handling** – Nodes can emit error states that divert execution to a fallback sub‑graph, improving robustness.\\n\\n### Typical Use Cases\\n\\n| Domain | Example Graph |\\n|--------|---------------|\\n| **Customer Support** | `UserMessage → IntentClassifier → (FAQRetriever, TicketCreator) → ResponseComposer`. ConditionalNode routes to FAQ if confidence >\\u202f0.8, otherwise creates a ticket. |\\n| **Financial Analysis** | `DataIngestion → Cleanser → LLMSummarizer → RiskEvaluator → DecisionNode`. Loop back to `Cleaner` if the evaluator flags inconsistencies. |\\n| **Education** | `Question → KnowledgeRetriever → LLMExplanation → QuizGenerator → FeedbackLoop`. The quiz node feeds results back into the retriever to personalize subsequent explanations. |\\n| **Enterprise Automation** | `TriggerEvent → PermissionChecker → (HRTool, FinanceTool) → AuditLogger`. Parallel branches handle HR and finance actions simultaneously, then merge for logging. |\\n\\n### Integration with the LangChain Ecosystem\\n\\nLangGraph is deliberately built to complement, not replace, LangChain:\\n\\n* **Prompt Templates** – You can reuse any `PromptTemplate` from LangChain inside an `LLMNode`.\\n* **Memory** – LangChain’s `ConversationBufferMemory`, `VectorStoreRetrieverMemory`, etc., can be wrapped as `MemoryNode`s, preserving the same API.\\n* **Agents** – Existing LangChain agents can be embedded as sub‑graphs, enabling hybrid approaches where an agent decides which sub‑graph to invoke.\\n* **Toolkits** – The same tool wrappers (e.g., `RequestsGetTool`, `SQLDatabaseTool`) are compatible with `ToolNode`.\\n\\n### Development Experience\\n\\n1. **Declarative Definition** – Graphs are defined via a high‑level DSL or programmatically with Python objects. Example:\\n\\n```python\\nfrom langgraph import Graph, LLMNode, ToolNode, ConditionalNode\\n\\ngraph = Graph(name=\"support_bot\")\\ngraph.add_node(\"classify_intent\", LLMNode(prompt=classify_prompt, model=\"gpt-4\"))\\ngraph.add_node(\"fetch_faq\", ToolNode(func=faq_retriever))\\ngraph.add_node(\"create_ticket\", ToolNode(func=ticket_creator))\\ngraph.add_node(\"compose_response\", LLMNode(prompt=compose_prompt))\\n\\ngraph.add_edge(\"classify_intent\", \"fetch_faq\", condition=lambda s: s[\"intent\"] == \"faq\")\\ngraph.add_edge(\"classify_intent\", \"create_ticket\", condition=lambda s: s[\"intent\"] != \"faq\")\\ngraph.add_edge([\"fetch_faq\", \"create_ticket\"], \"compose_response\")\\n```\\n\\n2. **Testing** – Because each node is an isolated function, unit tests can target individual components, while integration tests validate the graph traversal logic.\\n\\n3. **Observability** – The engine emits structured logs and traces for each node execution, making it straightforward to monitor latency, token usage, and error rates.\\n\\n### Performance and Scaling\\n\\nLangGraph’s parallel execution model can dramatically reduce end‑to‑end latency when multiple independent LLM calls or external API requests are needed. The library also supports:\\n\\n* **Batching** – Grouping similar LLM calls into a single request when the underlying model API permits it.\\n* **Caching** – Automatic memoization of node outputs based on input hashes, reducing redundant calls.\\n* **Distributed Execution** – With minimal changes, a graph can be dispatched across multiple workers (e.g., Ray, Dask), enabling horizontal scaling for high‑throughput workloads.\\n\\n### Future Directions\\n\\nThe community roadmap includes:\\n\\n* **Graph‑visualization UI** – Drag‑and‑drop builder for non‑programmers.\\n* **Typed State Schemas** – Enforcing contracts on the state dictionary to catch mismatches early.\\n* **Built‑in Reinforcement Learning loops** – Nodes that adjust prompts or tool parameters based on reward signals.\\n* **Cross‑language bindings** – Early prototypes for JavaScript/TypeScript and Rust, expanding the ecosystem beyond Python.\\n\\n### Closing Thoughts\\n\\nLangGraph transforms the way developers think about LLM‑centric applications. By elevating the workflow from a linear chain to a directed graph, it brings the expressive power of traditional software architecture—branching, looping, parallelism—into the realm of generative AI. This alignment makes it easier to build robust, maintainable, and scalable systems that can handle the nuanced, multi‑step reasoning required in production environments. Whether you’re constructing a simple FAQ bot or an enterprise‑grade decision engine, LangGraph offers a modular, observable, and extensible foundation that bridges the gap between prompt engineering and full‑stack software design.' additional_kwargs={'reasoning_content': 'The user asks: \"can you give me 500 words on langgraph?\" They want a 500-word piece on LangGraph. Likely they want a description, overview, features, use cases, etc. We can comply. It\\'s not disallowed. Provide about 500 words. Ensure it\\'s around 500 words (maybe 500 ± 20). Provide a well-structured answer.'} response_metadata={'token_usage': {'completion_tokens': 1627, 'prompt_tokens': 82, 'total_tokens': 1709, 'completion_time': 3.4281128450000002, 'prompt_time': 0.00293884, 'queue_time': 0.04790746, 'total_time': 3.431051685}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ed9190d8b7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--44b3e7ea-b0a8-4431-945b-26c1914a9c7b-0' usage_metadata={'input_tokens': 82, 'output_tokens': 1627, 'total_tokens': 1709}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content='**LangGraph: A 500‑Word Overview of the Emerging Framework for Building LLM‑Powered Applications**\\n\\nLangGraph is an open‑source Python library that extends the capabilities of LangChain by providing a graph‑oriented abstraction for orchestrating large language model (LLM) workflows. While LangChain introduced the notion of “chains” – linear sequences of prompts, tools, and memory – LangGraph adds a richer, more flexible topology: nodes represent individual computational steps (LLM calls, API invocations, data transformations, etc.), and edges define the flow of information between them. This graph‑centric view makes it easier to model complex, branching, and iterative reasoning patterns that are common in real‑world AI products.\\n\\n### Core Concepts\\n\\n1. **Nodes** – The atomic units of execution. A node can be:\\n   * **LLMNode** – wraps a prompt template, model, and optional output parsers.\\n   * **ToolNode** – calls an external function, API, or a custom Python routine.\\n   * **MemoryNode** – reads or writes to a persistent store (vector DB, key‑value cache, etc.).\\n   * **ConditionalNode** – evaluates a boolean expression and routes execution accordingly.\\n\\n2. **Edges** – Directed connections that pass data from one node’s output to another’s input. Edges can be annotated with transformation functions (e.g., “extract the `answer` field from the JSON payload”) so that downstream nodes receive exactly what they need.\\n\\n3. **State** – A mutable dictionary that lives throughout the graph run. Each node can read from or write to the state, enabling “memory” across multiple hops without the need for explicit chaining.\\n\\n4. **Execution Engine** – The runtime that traverses the graph. It supports:\\n   * **Depth‑first** or **breadth‑first** traversal.\\n   * **Parallel execution** of independent branches (leveraging asyncio or thread pools).\\n   * **Dynamic branching** where the next node is chosen at runtime based on model output or external conditions.\\n\\n5. **Serialization** – Graph definitions can be saved as JSON or YAML, allowing versioning, sharing, and deployment across environments.\\n\\n### Why a Graph Matters\\n\\nTraditional chain‑based pipelines excel at straightforward “prompt → response” flows, but many production scenarios require more sophisticated control flow:\\n\\n* **Iterative refinement** – A model may need to revise its answer after checking a knowledge base. LangGraph lets you loop back from a verification node to a generation node until a confidence threshold is met.\\n* **Multi‑modal reasoning** – Combining text generation, image analysis, and structured data lookup can be expressed as parallel sub‑graphs that synchronize at a merging node.\\n* **Conditional logic** – Business rules (e.g., “if the user is premium, call the premium‑rate API”) are naturally encoded with ConditionalNode edges.\\n* **Error handling** – Nodes can emit error states that divert execution to a fallback sub‑graph, improving robustness.\\n\\n### Typical Use Cases\\n\\n| Domain | Example Graph |\\n|--------|---------------|\\n| **Customer Support** | `UserMessage → IntentClassifier → (FAQRetriever, TicketCreator) → ResponseComposer`. ConditionalNode routes to FAQ if confidence >\\u202f0.8, otherwise creates a ticket. |\\n| **Financial Analysis** | `DataIngestion → Cleanser → LLMSummarizer → RiskEvaluator → DecisionNode`. Loop back to `Cleaner` if the evaluator flags inconsistencies. |\\n| **Education** | `Question → KnowledgeRetriever → LLMExplanation → QuizGenerator → FeedbackLoop`. The quiz node feeds results back into the retriever to personalize subsequent explanations. |\\n| **Enterprise Automation** | `TriggerEvent → PermissionChecker → (HRTool, FinanceTool) → AuditLogger`. Parallel branches handle HR and finance actions simultaneously, then merge for logging. |\\n\\n### Integration with the LangChain Ecosystem\\n\\nLangGraph is deliberately built to complement, not replace, LangChain:\\n\\n* **Prompt Templates** – You can reuse any `PromptTemplate` from LangChain inside an `LLMNode`.\\n* **Memory** – LangChain’s `ConversationBufferMemory`, `VectorStoreRetrieverMemory`, etc., can be wrapped as `MemoryNode`s, preserving the same API.\\n* **Agents** – Existing LangChain agents can be embedded as sub‑graphs, enabling hybrid approaches where an agent decides which sub‑graph to invoke.\\n* **Toolkits** – The same tool wrappers (e.g., `RequestsGetTool`, `SQLDatabaseTool`) are compatible with `ToolNode`.\\n\\n### Development Experience\\n\\n1. **Declarative Definition** – Graphs are defined via a high‑level DSL or programmatically with Python objects. Example:\\n\\n```python\\nfrom langgraph import Graph, LLMNode, ToolNode, ConditionalNode\\n\\ngraph = Graph(name=\"support_bot\")\\ngraph.add_node(\"classify_intent\", LLMNode(prompt=classify_prompt, model=\"gpt-4\"))\\ngraph.add_node(\"fetch_faq\", ToolNode(func=faq_retriever))\\ngraph.add_node(\"create_ticket\", ToolNode(func=ticket_creator))\\ngraph.add_node(\"compose_response\", LLMNode(prompt=compose_prompt))\\n\\ngraph.add_edge(\"classify_intent\", \"fetch_faq\", condition=lambda s: s[\"intent\"] == \"faq\")\\ngraph.add_edge(\"classify_intent\", \"create_ticket\", condition=lambda s: s[\"intent\"] != \"faq\")\\ngraph.add_edge([\"fetch_faq\", \"create_ticket\"], \"compose_response\")\\n```\\n\\n2. **Testing** – Because each node is an isolated function, unit tests can target individual components, while integration tests validate the graph traversal logic.\\n\\n3. **Observability** – The engine emits structured logs and traces for each node execution, making it straightforward to monitor latency, token usage, and error rates.\\n\\n### Performance and Scaling\\n\\nLangGraph’s parallel execution model can dramatically reduce end‑to‑end latency when multiple independent LLM calls or external API requests are needed. The library also supports:\\n\\n* **Batching** – Grouping similar LLM calls into a single request when the underlying model API permits it.\\n* **Caching** – Automatic memoization of node outputs based on input hashes, reducing redundant calls.\\n* **Distributed Execution** – With minimal changes, a graph can be dispatched across multiple workers (e.g., Ray, Dask), enabling horizontal scaling for high‑throughput workloads.\\n\\n### Future Directions\\n\\nThe community roadmap includes:\\n\\n* **Graph‑visualization UI** – Drag‑and‑drop builder for non‑programmers.\\n* **Typed State Schemas** – Enforcing contracts on the state dictionary to catch mismatches early.\\n* **Built‑in Reinforcement Learning loops** – Nodes that adjust prompts or tool parameters based on reward signals.\\n* **Cross‑language bindings** – Early prototypes for JavaScript/TypeScript and Rust, expanding the ecosystem beyond Python.\\n\\n### Closing Thoughts\\n\\nLangGraph transforms the way developers think about LLM‑centric applications. By elevating the workflow from a linear chain to a directed graph, it brings the expressive power of traditional software architecture—branching, looping, parallelism—into the realm of generative AI. This alignment makes it easier to build robust, maintainable, and scalable systems that can handle the nuanced, multi‑step reasoning required in production environments. Whether you’re constructing a simple FAQ bot or an enterprise‑grade decision engine, LangGraph offers a modular, observable, and extensible foundation that bridges the gap between prompt engineering and full‑stack software design.' additional_kwargs={'reasoning_content': 'The user asks: \"can you give me 500 words on langgraph?\" They want a 500-word piece on LangGraph. Likely they want a description, overview, features, use cases, etc. We can comply. It\\'s not disallowed. Provide about 500 words. Ensure it\\'s around 500 words (maybe 500 ± 20). Provide a well-structured answer.'} response_metadata={'token_usage': {'completion_tokens': 1627, 'prompt_tokens': 82, 'total_tokens': 1709, 'completion_time': 3.4281128450000002, 'prompt_time': 0.00293884, 'queue_time': 0.04790746, 'total_time': 3.431051685}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ed9190d8b7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--44b3e7ea-b0a8-4431-945b-26c1914a9c7b-0' usage_metadata={'input_tokens': 82, 'output_tokens': 1627, 'total_tokens': 1709}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bc19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 3.89 seconds\n",
      "content='**LangGraph: A 500‑Word Overview**\\n\\nLangGraph is an open‑source Python framework that extends the capabilities of the LangChain ecosystem by providing a structured, graph‑oriented way to design, orchestrate, and run complex multi‑step language‑model (LM) workflows. While LangChain introduced the idea of “chains”—linear sequences of prompts, tools, and memory—LangGraph adds a richer, non‑linear abstraction that mirrors real‑world decision trees, state machines, and conversational flows. This makes it especially suitable for applications that require branching logic, loops, conditional execution, or dynamic tool selection.\\n\\n---\\n\\n### Core Concepts\\n\\n1. **Nodes (Steps)**  \\n   A node represents a single unit of work: a prompt to an LLM, a call to an external API, a database query, or any custom Python function. Nodes are defined as `Runnable` objects (the same abstraction LangChain uses), allowing them to be composed, cached, and streamed.\\n\\n2. **Edges (Transitions)**  \\n   Edges connect nodes and dictate the flow of execution. Each edge can be unconditional (always follow) or conditional, based on the output of the source node. Conditions are expressed as Python callables that inspect the node’s result and return a Boolean, enabling branching and loop‑back behavior.\\n\\n3. **State Store**  \\n   LangGraph maintains a mutable state dictionary that travels with the execution context. Nodes can read from and write to this state, allowing information—like user preferences, intermediate results, or tool outputs—to be shared across the graph without resorting to global variables.\\n\\n4. **Graph Definition**  \\n   Graphs are declared declaratively using a simple DSL or programmatically with a `GraphBuilder`. The DSL looks like:\\n\\n   ```python\\n   graph = Graph()\\n   graph.add_node(\"greet\", greet_prompt)\\n   graph.add_node(\"search\", search_tool)\\n   graph.add_node(\"summarize\", summarize_prompt)\\n\\n   graph.add_edge(\"greet\", \"search\", condition=lambda s: \"search\" in s[\"intent\"])\\n   graph.add_edge(\"search\", \"summarize\")\\n   graph.add_edge(\"greet\", \"summarize\", condition=lambda s: s[\"intent\"] == \"summarize\")\\n   ```\\n\\n   This definition creates a flow where a greeting node decides whether to invoke a search tool before summarizing, or to skip straight to summarization.\\n\\n5. **Execution Engine**  \\n   The engine walks the graph depth‑first (or breadth‑first) respecting edge conditions, updating the shared state, and handling retries or fallbacks. It can run synchronously, asynchronously, or in a distributed fashion using Ray or Dask, making it scalable for high‑throughput services.\\n\\n---\\n\\n### Key Features\\n\\n- **Conditional Branching & Loops** – Unlike linear chains, LangGraph can express “if‑else”, “while”, and “for each” patterns directly in the graph, enabling sophisticated reasoning pipelines such as multi‑turn question answering, tool selection loops, or iterative refinement.\\n- **Tool Integration** – Nodes can wrap any callable, so you can attach search APIs, calculators, knowledge bases, or custom business logic. The framework automatically logs tool usage for observability.\\n- **Stateful Memory** – The built‑in state store replaces the need for external memory modules in many cases, while still allowing you to plug in LangChain’s VectorStore, Redis, or other persistent memories.\\n- **Visualization** – LangGraph ships with utilities to export the graph to DOT/Graphviz or Mermaid, giving developers an instant visual map of the workflow for debugging and documentation.\\n- **Observability & Tracing** – Each node execution is automatically instrumented with OpenTelemetry spans. Combined with LangChain’s “callbacks” system, you can monitor latency, token usage, and error rates per step.\\n- **Composable Sub‑graphs** – Complex applications can be broken into reusable sub‑graphs (mini‑workflows) that are then linked together, fostering modularity and code reuse.\\n\\n---\\n\\n### Typical Use Cases\\n\\n| Use Case | Why LangGraph Helps |\\n|----------|----------------------|\\n| **Multi‑tool Agents** | Dynamically select between search, calculator, or code execution based on LLM‑generated intent. |\\n| **Iterative Drafting** | Loop over “write → critique → improve” steps until a quality threshold is met. |\\n| **Conditional Customer Support** | Route a user query to FAQ retrieval, escalation, or live‑agent handoff based on confidence scores. |\\n| **Data‑driven Decision Pipelines** | Combine LLM reasoning with statistical models, feeding results back into the graph for re‑evaluation. |\\n| **Complex Conversational Games** | Model game states, branching storylines, and inventory management as graph nodes. |\\n\\n---\\n\\n### Simple Example: Research Assistant\\n\\n```python\\nfrom langgraph import Graph, Runnable\\nfrom langchain.llms import OpenAI\\nfrom my_tools import web_search, cite\\n\\n# Define reusable nodes\\ngather_intent = Runnable(lambda ctx: OpenAI().predict(\\n    f\"User query: {ctx[\\'input\\']}\\\\nWhat is the user\\'s intent? (search/summarize)\"))\\nsearch_node = Runnable(lambda ctx: web_search(ctx[\"query\"]))\\nsummarize_node = Runnable(lambda ctx: OpenAI().predict(\\n    f\"Summarize the following information:\\\\n{ctx[\\'content\\']}\"))\\n\\n# Build graph\\ngraph = Graph()\\ngraph.add_node(\"intent\", gather_intent)\\ngraph.add_node(\"search\", search_node)\\ngraph.add_node(\"summarize\", summarize_node)\\n\\ngraph.add_edge(\"intent\", \"search\",\\n               condition=lambda s: s[\"intent\"] == \"search\")\\ngraph.add_edge(\"search\", \"summarize\")\\ngraph.add_edge(\"intent\", \"summarize\",\\n               condition=lambda s: s[\"intent\"] == \"summarize\")\\n\\n# Execute\\nresult = graph.run({\"input\": \"Explain the impact of quantum computing on cryptography.\"})\\nprint(result[\"summarize\"])\\n```\\n\\nIn this snippet, the graph first asks the LLM to classify the request. If the intent is “search”, it calls a web‑search tool, then always passes the gathered content to a summarizer. The shared state (`ctx`) carries the original user input, the intent, and any intermediate results.\\n\\n---\\n\\n### Ecosystem & Community\\n\\nLangGraph is maintained by the same team behind LangChain and released under the MIT license. It lives in the `langgraph` PyPI package and integrates tightly with LangChain’s `Runnable`, `PromptTemplate`, and callback infrastructure. The project’s GitHub repository includes a growing collection of example graphs (agentic QA, autonomous agents, workflow automation) and a template for deploying graphs as FastAPI or AWS Lambda endpoints.\\n\\nBecause it builds on LangChain’s abstractions, developers can gradually adopt LangGraph: start with a simple chain, then refactor parts of it into nodes and edges as the logic becomes more complex. The community contributes custom node libraries (e.g., `langgraph‑sql`, `langgraph‑pdf`) and shares best‑practice patterns for error handling, token budgeting, and safe LLM usage.\\n\\n---\\n\\n### Outlook\\n\\nAs LLMs become more capable, the demand for robust orchestration layers grows. LangGraph’s graph‑centric model aligns well with emerging standards such as the OpenAI “function calling” paradigm and the “agentic workflow” patterns championed by AI‑first product teams. Future releases aim to add native support for:\\n\\n- **Dynamic graph generation** (graphs that mutate at runtime based on learned policies).  \\n- **Built‑in reinforcement‑learning loops** for self‑improving agents.  \\n- **Cross‑language bindings** (e.g., a TypeScript wrapper) to broaden adoption beyond Python.\\n\\nIn summary, LangGraph equips developers with a flexible, observable, and modular way to turn LLMs from single‑turn predictors into fully fledged, multi‑step reasoning engines. By treating each LM interaction, tool call, or data transformation as a node in a directed graph, it makes complex AI applications easier to design, test, and maintain—bringing us a step closer to production‑grade autonomous agents.' additional_kwargs={'reasoning_content': 'The user wants a 500-word piece on \"langgraph\". Likely they refer to LangGraph, a library for building LLM applications, part of LangChain ecosystem. Provide ~500 words. Should be concise, informative. Provide overview, features, architecture, use cases, examples. Ensure length approx 500 words.'} response_metadata={'token_usage': {'completion_tokens': 1758, 'prompt_tokens': 80, 'total_tokens': 1838, 'completion_time': 3.514071471, 'prompt_time': 0.003099441, 'queue_time': 0.053053198, 'total_time': 3.517170912}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_213abb2467', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--83620a98-e78f-4b08-b39e-ce05e773df33-0' usage_metadata={'input_tokens': 80, 'output_tokens': 1758, 'total_tokens': 1838}\n"
     ]
    }
   ],
   "source": [
    "query=\"give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083b6b7",
   "metadata": {},
   "source": [
    "### Advanced CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf663496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import TypedDict, List, Optional\n",
    "import time\n",
    "\n",
    "# ---- LangGraph / LangChain ----\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ---- FAISS vector stores ----\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb0e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIG =================\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384-dim\n",
    "VECTOR_DIM = 384\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0\n",
    "\n",
    "RETRIEVE_TOP_K = 4\n",
    "CACHE_TOP_K = 3\n",
    "\n",
    "CACHE_DISTANCE_THRESHOLD = 0.45\n",
    "\n",
    "# Optional TTL for cache entries (seconds). 0 = disabled.\n",
    "CACHE_TTL_SEC = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298cde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= STATE ==================\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    normalized_question: str\n",
    "    context_docs: List[Document]\n",
    "    answer: Optional[str]\n",
    "    citations: List[str]\n",
    "    cache_hit: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55558c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ChitreshKaushik\\Documents\\RAG_UseCases\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ============== GLOBALS ===================\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "EMBED = HuggingFaceEmbeddings(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9791f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- QA CACHE (EMPTY, SAFE INIT) -----\n",
    "qa_index = faiss.IndexFlatL2(VECTOR_DIM)  # distance; lower is better\n",
    "QA_CACHE = FAISS(\n",
    "    embedding_function=EMBED,\n",
    "    index=qa_index,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff36b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x292d224ba10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080fa22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- RAG STORE (demo only) -----\n",
    "RAG_STORE = FAISS.from_texts(\n",
    "    texts=[\n",
    "        \"LangGraph lets you compose stateful LLM workflows as graphs.\",\n",
    "        \"In LangGraph, nodes can be cached; node caching memoizes outputs keyed by inputs for a TTL.\",\n",
    "        \"Retrieval-Augmented Generation (RAG) retrieves external context and injects it into prompts.\",\n",
    "        \"Semantic caching reuses prior answers when new questions are semantically similar.\"\n",
    "    ],\n",
    "    embedding=EMBED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0cc311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d43f16f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000292E9152E40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000292E9153A10>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "997e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ NODES ===================\n",
    "def normalize_query(state: RAGState) -> RAGState:\n",
    "    q = (state[\"question\"] or \"\").strip()\n",
    "    state[\"normalized_question\"] = q.lower()\n",
    "    return state\n",
    "\n",
    "def semantic_cache_lookup(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    state[\"cache_hit\"] = False  # default\n",
    "\n",
    "    if not q:\n",
    "        return state\n",
    "\n",
    "    # ✅ Guard: FAISS crashes if ntotal == 0 and you ask for k>0\n",
    "    if getattr(QA_CACHE, \"index\", None) is None or QA_CACHE.index.ntotal == 0:\n",
    "        return state\n",
    "\n",
    "    # For FAISS L2 wrapper, this returns (Document, distance) with lower=better\n",
    "    hits = QA_CACHE.similarity_search_with_score(q, k=CACHE_TOP_K)\n",
    "    if not hits:\n",
    "        return state\n",
    "\n",
    "    best_doc, dist = hits[0]\n",
    "\n",
    "    # Optional TTL\n",
    "    if CACHE_TTL_SEC > 0:\n",
    "        ts = best_doc.metadata.get(\"ts\")\n",
    "        if ts is None or (time.time() - float(ts)) > CACHE_TTL_SEC:\n",
    "            return state\n",
    "\n",
    "    # L2 distance gate (lower = more similar)\n",
    "    if dist <= CACHE_DISTANCE_THRESHOLD:\n",
    "        cached_answer = best_doc.metadata.get(\"answer\")\n",
    "        if cached_answer:\n",
    "            state[\"answer\"] = cached_answer\n",
    "            state[\"citations\"] = [\"(cache)\"]\n",
    "            state[\"cache_hit\"] = True\n",
    "\n",
    "    return state\n",
    "\n",
    "def respond_from_cache(state: RAGState) -> RAGState:\n",
    "    return state\n",
    "\n",
    "def retrieve(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    docs = RAG_STORE.similarity_search(q, k=RETRIEVE_TOP_K)\n",
    "    state[\"context_docs\"] = docs\n",
    "    return state\n",
    "\n",
    "def generate(state: RAGState) -> RAGState:\n",
    "    q = state[\"question\"]\n",
    "    docs = state.get(\"context_docs\", [])\n",
    "    ctx = \"\\n\\n\".join([f\"[doc-{i}] {d.page_content}\" for i, d in enumerate(docs, start=1)])\n",
    "\n",
    "    system = (\n",
    "        \"You are a precise RAG assistant. Use the context when helpful. \"\n",
    "        \"Cite with [doc-i] markers if you use a fact from the context.\"\n",
    "    )\n",
    "    user = f\"Question: {q}\\n\\nContext:\\n{ctx}\\n\\nWrite a concise answer with citations.\"\n",
    "\n",
    "    resp = LLM.invoke([{\"role\": \"system\", \"content\": system},\n",
    "                       {\"role\": \"user\", \"content\": user}])\n",
    "    state[\"answer\"] = resp.content\n",
    "    state[\"citations\"] = [f\"[doc-{i}]\" for i in range(1, len(docs) + 1)]\n",
    "    return state\n",
    "\n",
    "def cache_write(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    a = state.get(\"answer\")\n",
    "    if not q or not a:\n",
    "        return state\n",
    "\n",
    "    QA_CACHE.add_texts(\n",
    "        texts=[q],\n",
    "        metadatas=[{\n",
    "            \"answer\": a,\n",
    "            \"ts\": time.time(),\n",
    "        }]\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "462f44af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000292D23D81A0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============== GRAPH WIRING ==============\n",
    "graph = StateGraph(RAGState)\n",
    "\n",
    "graph.add_node(\"normalize_query\", normalize_query)\n",
    "graph.add_node(\"semantic_cache_lookup\", semantic_cache_lookup)\n",
    "graph.add_node(\"respond_from_cache\", respond_from_cache)\n",
    "graph.add_node(\"retrieve\", retrieve)\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"cache_write\", cache_write)\n",
    "\n",
    "graph.set_entry_point(\"normalize_query\")\n",
    "graph.add_edge(\"normalize_query\", \"semantic_cache_lookup\")\n",
    "\n",
    "def _branch(state: RAGState) -> str:\n",
    "    return \"respond_from_cache\" if state.get(\"cache_hit\") else \"retrieve\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"semantic_cache_lookup\",\n",
    "    _branch,\n",
    "    {\n",
    "        \"respond_from_cache\": \"respond_from_cache\",\n",
    "        \"retrieve\": \"retrieve\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"respond_from_cache\", END)\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"cache_write\")\n",
    "graph.add_edge(\"cache_write\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = graph.compile(checkpointer=memory)\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba9bde2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph is a framework for building stateful LLM workflows as graph‑structured pipelines, letting you compose and orchestrate language‑model operations as interconnected nodes [doc‑2]. It also supports features such as node‑level caching, where a node’s output is memoized (keyed by its inputs) for a configurable time‑to‑live [doc‑1].\n",
      "Citations: ['[doc-1]', '[doc-2]', '[doc-3]', '[doc-4]']\n",
      "Cache hit?: False\n"
     ]
    }
   ],
   "source": [
    "# ================= DEMO ===================\n",
    "if __name__ == \"__main__\":\n",
    "    thread_cfg = {\"configurable\": {\"thread_id\": \"demo-user-1\"}}\n",
    "\n",
    "    q1 = \"What is LangGraph ?\"\n",
    "    out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "    print(\"Answer:\", out1[\"answer\"])\n",
    "    print(\"Citations:\", out1.get(\"citations\"))\n",
    "    print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2039bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph is a framework for building stateful LLM workflows as graph‑structured pipelines, letting you compose and orchestrate language‑model operations as interconnected nodes [doc‑2]. It also supports features such as node‑level caching, where a node’s output is memoized (keyed by its inputs) for a configurable time‑to‑live [doc‑1].\n",
      "Citations: ['(cache)']\n",
      "Cache hit?: True\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about LangGraph ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c8d9021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph agents are modular components that let you build **stateful LLM workflows as directed graphs**. Each node in the graph represents a step—such as prompting an LLM, calling a tool, or performing retrieval—and the agent’s state is passed along edges, enabling complex, multi‑turn interactions [doc-2].  \n",
      "\n",
      "Key features include:\n",
      "\n",
      "* **Node caching** – the output of a node can be memoized based on its inputs for a configurable time‑to‑live, so repeated calls with the same data are served instantly without re‑executing the LLM or tool [doc-1].  \n",
      "* **RAG integration** – agents can incorporate Retrieval‑Augmented Generation, pulling external documents and injecting them into prompts to ground the model’s responses [doc-3].  \n",
      "* **Semantic caching** – beyond exact matches, LangGraph can reuse prior answers when new queries are semantically similar, further speeding up the workflow [doc-4].\n",
      "\n",
      "Together, these capabilities let developers compose flexible, efficient, and context‑aware LLM agents that scale across many use‑cases.\n",
      "Citations: ['[doc-1]', '[doc-2]', '[doc-3]', '[doc-4]']\n",
      "Cache hit?: False\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about LangGraph agents ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d890c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph agents are modular components that let you build **stateful LLM workflows as directed graphs**. Each node in the graph represents a step—such as prompting an LLM, calling a tool, or performing retrieval—and the agent’s state is passed along edges, enabling complex, multi‑turn interactions [doc-2].  \n",
      "\n",
      "Key features include:\n",
      "\n",
      "* **Node caching** – the output of a node can be memoized based on its inputs for a configurable time‑to‑live, so repeated calls with the same data are served instantly without re‑executing the LLM or tool [doc-1].  \n",
      "* **RAG integration** – agents can incorporate Retrieval‑Augmented Generation, pulling external documents and injecting them into prompts to ground the model’s responses [doc-3].  \n",
      "* **Semantic caching** – beyond exact matches, LangGraph can reuse prior answers when new queries are semantically similar, further speeding up the workflow [doc-4].\n",
      "\n",
      "Together, these capabilities let developers compose flexible, efficient, and context‑aware LLM agents that scale across many use‑cases.\n",
      "Citations: ['(cache)']\n",
      "Cache hit?: True\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about agents in Langgraph ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
